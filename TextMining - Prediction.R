---
  title: "Text Mining - Assignment 3"
author: "Zohaib Sheikh, Shubham Khode, Anirudha Balkrishna"
date: "11/21/2021"
output: html_document
---
  
  **Loading relevant libraries**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
library(tidyverse)
library(tidytext)
library(lubridate)
library(data.table)
library(SnowballC)
library(textstem)
library(textdata)
library(rsample)
library(caret)
library(ranger)
library(glmnet)
library(e1071)
library(pROC)
library(writexl)
```

**Reading the Data**
  ```{r warning=FALSE,message=FALSE, error=FALSE}
#setwd("D:/Fall'21 - UIC/IDS 572 - Data Mining/Assignments/Assignment 4/yelpRestaurantReviews_sample_s21b")
data<-read_csv2("yelpRestaurantReviews_sample_s21b.csv")
```

**Understanding the Data**
  ```{r warning=FALSE,message=FALSE, error=FALSE}
glimpse(data)
length((unique(data$business_id)))
max(data$starsReview)
min(data$starsReview)
head(unique(data$name))
head(unique(data$neighborhood))
head(unique(data$state))
head(unique(data$is_open))
head(unique(data$categories))
```

**1. Data Exploration**
  ```{r warning=FALSE,message=FALSE, error=FALSE}
df<-data
df$Review<-as.factor(df$starsReview)
unique(df$Review)
```

**a. Distribution of STAR Ratings - Overall**
  ```{r warning=FALSE,message=FALSE, error=FALSE}
qplot(df$Review, geom = "bar",xlab='Distribution of Ratings')
```

**a. Distribution of STAR Ratings - By State**
  ```{r warning=FALSE,message=FALSE, error=FALSE}
df_bar<-df%>%group_by(state)%>%summarise(num_ratings=n(), 
                                         num_5_rat=round(sum(starsReview==5)*100/num_ratings),
                                         num_4_rat=round(sum(starsReview==4)*100/num_ratings),
                                         num_3_rat=round(sum(starsReview==3)*100/num_ratings),
                                         num_2_rat=round(sum(starsReview==2)*100/num_ratings),
                                         num_1_rat=round(sum(starsReview==1)*100/num_ratings))%>%arrange(desc(num_ratings))
df_bar
barplot(height=df_bar$num_ratings, names.arg = df_bar$state,xlab='Distribution of Ratings by state',col = 'blue')
df_bar2<-df%>%group_by(Review,state)%>%summarise(num_ratings=n())
ggplot(data = df_bar2, mapping = aes(x=Review, y=num_ratings, fill=state)) +  geom_col()
```

**Do star ratings have any relation to 'funny', 'cool', 'useful'? Is this what you expected?**
  ```{r warning=FALSE,message=FALSE, error=FALSE}
ggplot(df, aes(x= useful, y=starsReview)) +geom_point()
ggplot(df, aes(x= funny, y=starsReview)) +geom_point()
ggplot(df, aes(x= cool, y=starsReview)) +geom_point()
ggplot(df, aes(x= cool, y=funny)) +geom_point()
df%>%group_by(Review)%>%summarise(num_ratings=n(),sum_useful=sum(useful),sum_cool=sum(cool),sum_funny=sum(funny))%>%arrange(desc(sum_useful))
```

**Star Ratings relation with Business Star Ratings**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
ggplot(data=df,mapping= aes(x=starsReview,y=starsBusiness))+geom_point()
max(df$starsBusiness)
df%>%group_by(starsBusiness)%>%summarise(num_ratings=n(), 
                                         num_5_rat=round(sum(starsReview==5)*100/num_ratings),
                                         num_4_rat=round(sum(starsReview==4)*100/num_ratings),
                                         num_3_rat=round(sum(starsReview==3)*100/num_ratings),
                                         num_2_rat=round(sum(starsReview==2)*100/num_ratings),
                                         num_1_rat=round(sum(starsReview==1)*100/num_ratings)) %>%arrange(desc(num_ratings))%>%arrange(desc(starsBusiness))
```

**Tokenize the reviews - tokenize the text of the reviews in the column named 'text'**
``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens <- df %>% select(review_id,starsReview, text) %>% unnest_tokens(word, text)
dim(df_Tokens)
head(df_Tokens)
```

**Number of Distinct Words**
``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens %>% distinct(word) %>% dim()
```

**Removing Stop words**
``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens <- df_Tokens %>% anti_join(stop_words)
```

**Count the total occurrences of different words, & sort by most frequent**
``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens %>% count(word, sort=TRUE) %>% top_n(10)
```

**Let's remove the words which are not present in at least 10 reviews**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
rareWords <-df_Tokens %>% count(word, sort=TRUE) %>% filter(n<10)
df_Tokens1<-anti_join(df_Tokens, rareWords)
df_Tokens1 %>% count(word, sort=TRUE) %>% view()
```

**Remove the terms containing digits**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens1 <- df_Tokens1 %>% filter(str_detect(word,"[0-9]") == FALSE)
length(unique(df_Tokens1$word))
head(df_Tokens1)
```

**Filtered Tokens**
  ```{r warning=FALSE}
revTokens <- df_Tokens1 #To be used later while building model
revTokens <- revTokens %>% filter(between(nchar(word), 3, 15))
```

**Words Associated with different STAR ratings**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens1 %>% group_by(starsReview) %>% count(word, sort=TRUE)

df_Tokens_stars <- df_Tokens1 %>% group_by(starsReview) %>% count(word, sort=TRUE)
df_Tokens_stars<- df_Tokens_stars %>% group_by(starsReview) %>% mutate(prop=n/sum(n))

df_Tokens_stars %>% group_by(starsReview) %>% arrange(desc(starsReview), desc(prop)) %>% filter(row_number()<=20)%>%ggplot(aes(word, prop))+geom_col()+coord_flip()+facet_wrap((~starsReview))
```

**Positive and Negative label using words associated with star ratings**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
pos_neg_rat_stars<- df_Tokens_stars %>% group_by(starsReview) %>% arrange(desc(starsReview), desc(prop)) %>% filter(row_number()<=20)%>% left_join( get_sentiments("bing"), by="word")%>%view()
pos_neg_rat_stars <- pos_neg_rat_stars %>% na_if("NA")
unique(pos_neg_rat_stars$sentiment)
ggplot(data = pos_neg_rat_stars, mapping = aes(x=sentiment, y=n, fill=starsReview)) +  geom_col()
```

**2. Average star rating associated with each word**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_stars$char_len<-nchar(df_Tokens_stars$word)
df_Tokens_stars<-df_Tokens_stars%>%filter(char_len>=3)
df_Tokens_stars_avg<-df_Tokens_stars %>% group_by(word) %>% summarise( avg = sum(starsReview*prop))
df_Tokens_stars_avg%>%top_n(20)
df_Tokens_stars_avg%>%top_n(-20)
```

**3. Dictionary Matching**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
head(get_sentiments("bing"),10)
head(get_sentiments("nrc"),10)
head(get_sentiments("afinn"),10)
```

**With Bing**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_bing<- df_Tokens %>% left_join( get_sentiments("bing"), by="word")
df_Tokens_bing <- df_Tokens_bing %>% na_if("NA")
df_Tokens_bing%>%group_by(sentiment)%>%summarise(n=n_distinct(word))%>%ggplot(aes(sentiment, n))+geom_col()+geom_text(aes(label = n), vjust = -0.2, colour = "blue")
```

**With NRC**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_nrc<- df_Tokens %>% left_join( get_sentiments("nrc"), by="word")
df_Tokens_nrc <- df_Tokens_nrc %>% na_if("NA")
df_Tokens_nrc%>%group_by(sentiment)%>%summarise(n=n_distinct(word))%>%ggplot(aes(sentiment,n))+geom_col()+geom_text(aes(label = n), vjust = -0.2, colour = "blue") +theme(plot.margin=unit(c(2,2,2.5,2.2),"cm"))
```

**With Afinn**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_afinn<- df_Tokens %>% left_join( get_sentiments("afinn"), by="word")
df_Tokens_afinn <- df_Tokens_afinn %>% na_if("NA")
df_Tokens_afinn%>%group_by(value)%>%summarise(n=n_distinct(word))%>%ggplot(aes(value, n))+geom_col()+geom_text(aes(label = n), vjust = -0.2, colour = "blue")+theme(plot.margin=unit(c(1,1,1.5,1.2),"cm"))
```

**Lemmatize and Filter**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens1$char_len<-nchar(df_Tokens1$word)
df_Tokens2<-df_Tokens1%>%filter(char_len>=3)
df_Tokens3<-df_Tokens2%>%group_by(review_id,starsReview,word)%>%summarise(n=n())
df_Tokens3<-df_Tokens3 %>% mutate(word = textstem::lemmatize_words(word))
df_Tokens3<-df_Tokens3 %>% bind_tf_idf(word, review_id, n)
```

**Positive and Negative sentiments scores by words from Bing** 
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_bing<- df_Tokens3 %>% inner_join( get_sentiments("bing"), by="word")
df_Tokens_bing1<-df_Tokens_bing %>% group_by(word, sentiment) %>% summarise(totOcc=sum(n)) %>% arrange(sentiment, desc(totOcc))
df_Tokens_bing1<- df_Tokens_bing1 %>% mutate (totOcc=ifelse(sentiment=="positive", totOcc, -totOcc))
df_Tokens_bing1<-ungroup(df_Tokens_bing1)
df_Tokens_bing1 %>% top_n(25)
df_Tokens_bing1 %>% top_n(-25)
```

**Analysis based on review sentiment - BING**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_bing2 <- df_Tokens_bing %>% group_by(review_id, starsReview) %>%
  summarise(nwords=n(),posSum=sum(sentiment=='positive'),
            negSum=sum(sentiment=='negative'))
df_Tokens_bing2<- df_Tokens_bing2 %>% mutate(posProp=posSum/nwords, negProp=negSum/nwords)
df_Tokens_bing2<- df_Tokens_bing2%>% mutate(sentiScore=posProp-negProp)
df_Tokens_bing2 %>% group_by(starsReview) %>%
  summarise(avgPos=mean(posProp), avgNeg=mean(negProp), avgSentiSc=mean(sentiScore))
```

**Analysis based on review sentiment - NRC**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_nrc<- df_Tokens3 %>% inner_join( get_sentiments("nrc"), by="word")
df_Tokens_nrc2<-df_Tokens_nrc %>% summarise(nwords=n(),negSum=sum(sentiment %in% c('anger', 'disgust', 'fear', 'sadness', 'negative')),posSum=sum(sentiment %in% c('positive', 'joy', 'anticipation', 'trust')))                                                                                                        
df_Tokens_nrc2<- df_Tokens_nrc2 %>% mutate(posProp=posSum/nwords, negProp=negSum/nwords)
df_Tokens_nrc2<- df_Tokens_nrc2%>% mutate(sentiScore=posProp-negProp)
df_Tokens_nrc2 %>% group_by(starsReview) %>%
  summarise(avgPos=mean(posProp), avgNeg=mean(negProp), avgSentiSc=mean(sentiScore))
```

**Analysis based on review sentiment - AFINN**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_afinn<- df_Tokens3 %>% inner_join(get_sentiments("afinn"), by="word")
df_Tokens_afinn2 <- df_Tokens_afinn %>% group_by(review_id, starsReview)%>% summarise(nwords=n(), sentiSum =sum(value))
df_Tokens_afinn2 %>% group_by(starsReview)%>% summarise(avgLen=mean(nwords), avgSenti=mean(sentiSum))
```

**Predictions based on aggregated Scores - BING**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_bing3 <- df_Tokens_bing2 %>% mutate(hiLo = ifelse(starsReview <= 2, -1, ifelse(starsReview >=4, 1, 0 )))
df_Tokens_bing3 <- df_Tokens_bing3 %>% mutate(pred_hiLo=if_else(sentiScore > 0, 1, -1))
df_Tokens_bing4<-df_Tokens_bing3 %>% filter(hiLo!=0)
table(actual=df_Tokens_bing4$hiLo, predicted=df_Tokens_bing4$pred_hiLo )
```

**Predictions based on aggregated Scores - NRC**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_nrc3 <- df_Tokens_nrc2 %>% mutate(hiLo = ifelse(starsReview <= 2, -1, ifelse(starsReview >=4, 1, 0 )))
df_Tokens_nrc3 <- df_Tokens_nrc3 %>% mutate(pred_hiLo=if_else(sentiScore > 0, 1, -1))
df_Tokens_nrc4<-df_Tokens_nrc3 %>% filter(hiLo!=0)
table(actual=df_Tokens_nrc4$hiLo, predicted=df_Tokens_nrc4$pred_hiLo )
```

**Predictions based on aggregated Scores - AFINN**
  ``` {r warning=FALSE,message=FALSE, error=FALSE}
df_Tokens_afinn3 <- df_Tokens_afinn2 %>% mutate(hiLo = ifelse(starsReview <= 2, -1, ifelse(starsReview >=4, 1, 0 )))
df_Tokens_afinn3 <- df_Tokens_afinn3 %>% mutate(pred_hiLo=if_else(sentiSum > 0, 1, -1))
df_Tokens_afinn4<-df_Tokens_afinn3 %>% filter(hiLo!=0)
table(actual=df_Tokens_afinn4$hiLo, predicted=df_Tokens_afinn4$pred_hiLo )
```

**3. Preparing data for building models**
  ```{r warning=FALSE}
revTokens_lemm <- revTokens %>% mutate(word = textstem::lemmatize_words(word)) 

#Bing
r_bing <- revTokens_lemm %>% inner_join(get_sentiments("bing"), by="word")
r_bing <- r_bing %>% group_by(review_id, starsReview) %>% count(word) %>% bind_tf_idf(word, review_id, n)
dtm_bing <- r_bing %>% pivot_wider(id_cols = c(review_id, starsReview), names_from = word, values_from = tf_idf) %>% ungroup()
dtm_bing <- dtm_bing %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
dtm_bing %>% group_by(hiLo) %>% tally()
dtm_bing <- dtm_bing %>% replace(., is.na(.), 0) 
dtm_bing$hiLo <- as.factor(dtm_bing$hiLo)

dtm_bing_split<- initial_split(dtm_bing, 0.7) 
bing_trn <- training(dtm_bing_split) 
bing_tst <- testing(dtm_bing_split)
bing_trn <- bing_trn %>% select(-review_id)
bing_tst <- bing_tst %>% select(-review_id)
rm(dtm_bing_split) #Clearing objects taking up memory and no longer required

#NRC
r_nrc<- revTokens_lemm %>% inner_join(distinct(get_sentiments("nrc")[,1]), by="word")
r_nrc <- r_nrc %>% group_by(review_id, starsReview) %>% count(word) %>% bind_tf_idf(word, review_id, n)
dtm_nrc <- r_nrc %>% pivot_wider(id_cols = c(review_id, starsReview), names_from = word, values_from = tf_idf) %>% ungroup()
dtm_nrc <- dtm_nrc %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
dtm_nrc %>% group_by(hiLo) %>% tally()
dtm_nrc <- dtm_nrc %>% replace(., is.na(.), 0) 
dtm_nrc$hiLo <- as.factor(dtm_nrc$hiLo)

dtm_nrc_split<- initial_split(dtm_nrc, 0.7) 
nrc_trn <- training(dtm_nrc_split) 
nrc_tst <- testing(dtm_nrc_split)
nrc_trn <- nrc_trn %>% select(-review_id)
nrc_tst <- nrc_tst %>% select(-review_id)
rm(dtm_nrc_split) #Clearing objects taking up memory and no longer required

#AFINN
r_afinn<- revTokens_lemm %>% inner_join(get_sentiments("afinn"), by="word")
r_afinn <- r_afinn %>% group_by(review_id, starsReview) %>% count(word) %>% bind_tf_idf(word, review_id, n)
dtm_afinn <- r_afinn %>% pivot_wider(id_cols = c(review_id, starsReview), names_from = word, values_from = tf_idf) %>% ungroup()
dtm_afinn <- dtm_afinn %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
dtm_afinn %>% group_by(hiLo) %>% tally()
dtm_afinn <- dtm_afinn %>% replace(., is.na(.), 0) 
dtm_afinn$hiLo <- as.factor(dtm_afinn$hiLo)

dtm_afinn_split<- initial_split(dtm_afinn, 0.7) 
afinn_trn <- training(dtm_afinn_split) 
afinn_tst <- testing(dtm_afinn_split)
afinn_trn <- afinn_trn %>% select(-review_id)
afinn_tst <- afinn_tst %>% select(-review_id)
rm(dtm_afinn_split) #Clearing objects taking up memory and no longer required

#Combined - Bing, NRC, AFINN
bing_words <- get_sentiments("bing")[,1]
nrc_words <- get_sentiments("nrc")[,1]
affin_words <- get_sentiments("afinn")[,1] 
combinedWords <- rbind(bing_words, nrc_words, affin_words)
combinedWords <- distinct(combinedWords)

r_combined <- revTokens_lemm %>% inner_join(combinedWords, by="word")
r_combined <- r_combined %>% group_by(review_id, starsReview) %>% count(word) %>% bind_tf_idf(word, review_id, n)
dtm_combined <- r_combined %>% pivot_wider(id_cols = c(review_id, starsReview), names_from = word, values_from = tf_idf) %>% ungroup()
dtm_combined <- dtm_combined %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
dtm_combined %>% group_by(hiLo) %>% tally()
dtm_combined <- dtm_combined %>% replace(., is.na(.), 0) 
dtm_combined$hiLo <- as.factor(dtm_combined$hiLo)

dtm_combined_split<- initial_split(dtm_combined, 0.7) 
combined_trn <- training(dtm_combined_split) 
combined_tst <- testing(dtm_combined_split)
combined_trn1 <- combined_trn %>% select(-review_id)
combined_tst1 <- combined_tst %>% select(-review_id)
rm(dtm_combined_split) #Clearing objects taking up memory and no longer required

#Broader set of words
rWords <- revTokens_lemm %>% group_by(word) %>% summarise(freq=n()) %>% arrange(desc(freq)) 
rWords <- rWords %>% mutate(rank=seq(1, nrow(rWords)))
plot(rWords$rank, rWords$freq, xlab = "Rank" , ylab = "Frequency")
rWords <- rWords %>% mutate(logRank=log(seq(1, nrow(rWords))))
plot(rWords$logRank, rWords$freq, xlab = "Log(Rank)" , ylab = "Frequency")
reduced_rWords <- rWords %>% filter(between(logRank, 3, 8)) %>% select(word)

reduced_revTokens <- revTokens_lemm %>% inner_join(reduced_rWords, by="word")
reduced_revTokens <- reduced_revTokens %>% group_by(review_id, starsReview) %>% count(word) %>% bind_tf_idf(word, review_id, n)
dtm_broader_words <- reduced_revTokens %>% pivot_wider(id_cols = c(review_id, starsReview), names_from = word, values_from = tf_idf) %>% ungroup()
dtm_broader_words <- dtm_broader_words %>% filter(starsReview!=3) %>% mutate(hiLo=ifelse(starsReview<=2, -1, 1)) %>% select(-starsReview)
dtm_broader_words %>% group_by(hiLo) %>% tally()
dtm_broader_words <- dtm_broader_words %>% replace(., is.na(.), 0) 
dtm_broader_words$hiLo <- as.factor(dtm_broader_words$hiLo)

dtm_broader_words_split<- initial_split(dtm_broader_words, 0.7) 
broader_words_trn <- training(dtm_broader_words_split) 
broader_words_tst <- testing(dtm_broader_words_split)
broader_words_trn <- broader_words_trn %>% select(-review_id)
broader_words_tst <- broader_words_tst %>% select(-review_id)
rm(dtm_broader_words_split) #Clearing objects taking up memory and no longer required
```

**Model 1 - Random Forrest**
  ```{r warning=FALSE}
gridSearchRF<- function(mtry.values, trn.data.set){
  
  search_grid_rf <- expand.grid(
    mtry       = mtry.values,
    num.trees  = seq(100, 500, by = 100),
    OOB.error  = 0
  )
  
  for(i in 1:nrow(search_grid_rf)) {
    rfModel <- ranger(
      dependent.variable.name = "hiLo", 
      data        = trn.data.set, 
      mtry        = search_grid_rf$mtry[i], 
      num.trees   = search_grid_rf$num.trees[i],
      probability = TRUE
    )
    search_grid_rf$OOB.error[i] <- rfModel$prediction.error
  }
  
  return(search_grid_rf %>% dplyr::arrange(OOB.error))
}

#Bing
rfModel1GridSearch <- gridSearchRF(seq(30, 36, by = 3), bing_trn)
rfModel1<-ranger(dependent.variable.name = "hiLo", data=bing_trn, mtry = rfModel1GridSearch[1,"mtry"], num.trees = rfModel1GridSearch[1,"num.trees"], probability = TRUE)

#NRC
rfModel2GridSearch <- gridSearchRF(seq(36, 43, by = 3), nrc_trn)
rfModel2<-ranger(dependent.variable.name = "hiLo", data=nrc_trn, mtry = rfModel2GridSearch[1,"mtry"], num.trees = rfModel2GridSearch[1,"num.trees"], probability = TRUE)

#AFINN
rfModel3GridSearch <- gridSearchRF(seq(23, 29, by = 3), afinn_trn)
rfModel3<-ranger(dependent.variable.name = "hiLo", data=afinn_trn, mtry = rfModel3GridSearch[1,"mtry"], num.trees = rfModel3GridSearch[1,"num.trees"], probability = TRUE)

#Combined - Bing, NRC, AFINN
rfModel4GridSearch <- gridSearchRF(seq(43, 49, by = 3), combined_trn1)
rfModel4<-ranger(dependent.variable.name = "hiLo", data=combined_trn1, mtry = rfModel4GridSearch[1,"mtry"], num.trees = rfModel4GridSearch[1,"num.trees"], probability = TRUE)

#Broader set of words
rfModel5GridSearch <- gridSearchRF(seq(51, 57, by = 3), broader_words_trn)
rfModel5<-ranger(dependent.variable.name = "hiLo", data=broader_words_trn, mtry = rfModel5GridSearch[1,"mtry"], num.trees = rfModel5GridSearch[1,"num.trees"], probability = TRUE)

##Broader set of words - Tuned
rfModel5Tuned<-ranger(dependent.variable.name = "hiLo", data = broader_words_trn, mtry = 27, num.trees = 250, probability = TRUE, min.node.size = 5, sample.fraction = 0.5)

#Writing Grid Search - only for reference
write_xlsx(rfModel1GridSearch,"RFModels_Bing.xlsx")
write_xlsx(rfModel2GridSearch,"RFModels_NRC.xlsx")
write_xlsx(rfModel3GridSearch,"RFModels_AFINN.xlsx")
write_xlsx(rfModel4GridSearch,"RFModels_Combined.xlsx")
write_xlsx(rfModel5GridSearch,"RFModels_BroaderWords.xlsx")
```

**Performance Evaluation - Model 1 - Random Forrest**
  ```{r warning=FALSE}
#Evaluation - Test & Train
evalTrainTestRF <- function(model, trn_data, tst_data){
  pred_trn <- predict(model, trn_data)$predictions 
  pred_tst <- predict(model, tst_data)$predictions
  
  print(table(actual=trn_data$hiLo, preds=pred_trn[,2]>0.4)) 
  print(table(actual=tst_data$hiLo, preds=pred_tst[,2]>0.4))
  
  roc(trn_data$hiLo, pred_trn[,2], plot=TRUE, legacy.axes=TRUE, xlab="False Positive Rate", ylab="True Postive Rate", col="#377eb8", lwd=4, print.auc=TRUE)
  plot.roc(tst_data$hiLo, pred_tst[,2], col="#4daf4a", lwd=4, print.auc=TRUE, print.auc.y = 0.45, add=TRUE)
  legend("bottomright", legend=c("Training", "Test"), col=c("#377eb8", "#4daf4a"), lwd=4)
}

#Bing
evalTrainTestRF(rfModel1, bing_trn, bing_tst)

#NRC
evalTrainTestRF(rfModel2, nrc_trn, nrc_tst)

#AFINN
evalTrainTestRF(rfModel3, afinn_trn, afinn_tst)

#Combined - Bing, NRC, AFINN
evalTrainTestRF(rfModel4, combined_trn1, combined_tst1)

#Broader set of words
evalTrainTestRF(rfModel5, broader_words_trn, broader_words_tst)

#Broader set of words - Tuned
evalTrainTestRF(rfModel5Tuned, broader_words_trn, broader_words_tst)
```

**Model 2 - NB**
  ```{r warning=FALSE}
#Tuning grid
search_grid_nb <- expand.grid(
  usekernel = c(TRUE, FALSE),
  laplace = 0:3,
  adjust = seq(0, 3, by = 0.5)
)

#Bing
nbModel1<- train(
  hiLo ~ .,
  data = bing_trn,
  method = "naive_bayes",
  trControl = trainControl(method='cv',number=10),
  tuneGrid = search_grid_nb,
)

laplace1  = nbModel1$bestTune[1,1]
usekernel1 = nbModel1$bestTune[1,2]
adjust1 = nbModel1$bestTune[1,3]
nbModel1 <- naiveBayes(hiLo ~ ., data = bing_trn, laplace = laplace1, usekernel = usekernel1, adjust = adjust1)

#NRC
nbModel2 <- train(
  hiLo ~ .,
  data = nrc_trn,
  method = "naive_bayes",
  trControl = trainControl(method='cv',number=10),
  tuneGrid = search_grid_nb,
)

laplace2  = nbModel2$bestTune[1,1]
usekernel2 = nbModel2$bestTune[1,2]
adjust2 = nbModel2$bestTune[1,3]
nbModel2 <- naiveBayes(hiLo ~ ., data = nrc_trn, laplace = laplace2, usekernel = usekernel2, adjust = adjust2)

#AFINN
nbModel3 <- train(
  hiLo ~ .,
  data = afinn_trn,
  method = "naive_bayes",
  trControl = trainControl(method='cv',number=10),
  tuneGrid = search_grid_nb,
)

laplace3  = nbModel3$bestTune[1,1]
usekernel3 = nbModel3$bestTune[1,2]
adjust3 = nbModel3$bestTune[1,3]
nbModel3 <- naiveBayes(hiLo ~ ., data = afinn_trn, laplace = laplace3, usekernel = usekernel3, adjust = adjust3)

#Combined - Bing, NRC, AFINN
nbModel4 <- train(
  hiLo ~ .,
  data = combined_trn,
  method = "naive_bayes",
  trControl = trainControl(method='cv',number=10),
  tuneGrid = search_grid_nb,
)

laplace4  = nbModel4$bestTune[1,1]
usekernel4 = nbModel4$bestTune[1,2]
adjust4 = nbModel4$bestTune[1,3]
nbModel4 <- naiveBayes(hiLo ~ ., data = combined_trn, laplace = laplace4, usekernel = usekernel4, adjust = adjust4)

#Broader set of words
nbModel5 <- train(
  hiLo ~ .,
  data = broader_words_trn,
  method = "naive_bayes",
  trControl = trainControl(method='cv',number=10),
  tuneGrid = search_grid_nb,
)

laplace5  = nbModel5$bestTune[1,1]
usekernel5 = nbModel5$bestTune[1,2]
adjust5 = nbModel5$bestTune[1,3]
nbModel5 <- naiveBayes(hiLo ~ ., data = broader_words_trn, laplace = laplace5, usekernel = usekernel5, adjust = adjust5)
```

**Performance Evaluation - Model 2 - NB**
  ```{r warning=FALSE}
#Evaluation - Test & Train
evalTrainTestNB <- function(model, trn_data, tst_data){
  pred_trn <- predict(model, trn_data, type = "raw")
  pred_tst <- predict(model, tst_data, type = "raw")
  
  print(table(actual=trn_data$hiLo, preds=pred_trn[,2]>0.4)) 
  print(table(actual=tst_data$hiLo, preds=pred_tst[,2]>0.4))
  
  roc(trn_data$hiLo, pred_trn[,2], plot=TRUE, legacy.axes=TRUE, xlab="False Positive Rate", ylab="True Postive Rate", col="#377eb8", lwd=4, print.auc=TRUE)
  plot.roc(tst_data$hiLo, pred_tst[,2], col="#4daf4a", lwd=4, print.auc=TRUE, print.auc.y = 0.45, add=TRUE)
  legend("bottomright", legend=c("Training", "Test"), col=c("#377eb8", "#4daf4a"), lwd=4)
}

#Bing
evalTrainTestNB(nbModel1, bing_trn, bing_tst)

#NRC
evalTrainTestNB(nbModel2, nrc_trn, nrc_tst)

#AFINN
evalTrainTestNB(nbModel3, afinn_trn, afinn_tst)

#Combined - Bing, NRC, AFINN
evalTrainTestNB(nbModel4, combined_trn, combined_tst)

#Broader set of words
evalTrainTestNB(nbModel5, broader_words_trn, broader_words_tst)
```

**Model 3 - Lasso Logistic Regression**
  ```{r}
#Bing
x1 = select(bing_trn, -hiLo) 
y1 = bing_trn$hiLo
cvglmModel1 <- cv.glmnet(data.matrix(x1), y1, family = "binomial", alpha = 1)

nzCoef1 <- tidy(coef(cvglmModel1, s=cvglmModel1$lambda.min))
nzCoefVars1 <- nzCoef1[-1,1]
x1 <- bing_trn %>% select(nzCoefVars1)
x1$hiLo <- bing_trn$hiLo
x1_tst <- bing_tst %>% select(nzCoefVars1)
x1_tst$hiLo <- bing_tst$hiLo
glmModel1 <- glm(formula = hiLo ~ ., data = x1, family = "binomial")

#NRC
x2 = select(nrc_trn, -hiLo) 
y2 = nrc_trn$hiLo
cvglmModel2 <- cv.glmnet(data.matrix(x2), y2, family = "binomial", alpha = 1)

nzCoef2 <- tidy(coef(cvglmModel2, s=cvglmModel2$lambda.min))
nzCoefVars2 <- nzCoef2[-1,1]
x2 <- nrc_trn %>% select(nzCoefVars2)
x2$hiLo <- nrc_trn$hiLo
x2_tst <- nrc_tst %>% select(nzCoefVars2)
x2_tst$hiLo <- nrc_tst$hiLo
glmModel2 <- glm(formula = hiLo ~ ., data = x2, family = "binomial")

#AFINN
x3 = select(afinn_trn, -hiLo) 
y3 = afinn_trn$hiLo
cvglmModel3 <- cv.glmnet(data.matrix(x3), y3, family = "binomial", alpha = 1)

nzCoef3 <- tidy(coef(cvglmModel3, s=cvglmModel3$lambda.min))
nzCoefVars3 <- nzCoef3[-1,1]
x3 <- afinn_trn %>% select(nzCoefVars3)
x3$hiLo <- afinn_trn$hiLo
x3_tst <- afinn_tst %>% select(nzCoefVars3)
x3_tst$hiLo <- afinn_tst$hiLo
glmModel3 <- glm(formula = hiLo ~ ., data = x3, family = "binomial")

#Combined - Bing, NRC, AFINN
x4 = select(combined_trn, -hiLo) 
y4 = combined_trn$hiLo
cvglmModel4 <- cv.glmnet(data.matrix(x4), y4, family = "binomial", alpha = 1)

nzCoef4 <- tidy(coef(cvglmModel4, s=cvglmModel4$lambda.min))
nzCoefVars4 <- nzCoef4[-1,1]
x4 <- combined_trn %>% select(nzCoefVars4)
x4$hiLo <- combined_trn$hiLo
x4_tst <- combined_tst %>% select(nzCoefVars4)
x4_tst$hiLo <- combined_tst$hiLo
glmModel4 <- glm(formula = hiLo ~ ., data = x4, family = "binomial")

#Broader set of words
x5 = select(broader_words_trn, -hiLo) 
y5 = broader_words_trn$hiLo
cvglmModel5 <- cv.glmnet(data.matrix(x5), y5, family = "binomial", alpha = 1)

nzCoef5 <- tidy(coef(cvglmModel5, s=cvglmModel5$lambda.min))
nzCoefVars5 <- nzCoef5[-1,1]
x5 <- broader_words_trn %>% select(nzCoefVars5)
x5$hiLo <- broader_words_trn$hiLo
x5_tst <- broader_words_tst %>% select(nzCoefVars5)
x5_tst$hiLo <- broader_words_tst$hiLo
glmModel5 <- glm(formula = hiLo ~ ., data = x5, family = "binomial")
```

**Performance Evaluation - Model 3 - Lasso Logistic Regression**
  ```{r warning=FALSE}
#Evaluation - Test & Train
evalTrainTestLM <- function(model, trn_data, tst_data){
  
  pred_trn_resp <- predict(model, newdata = trn_data, type = "response")
  pred_trn <-as.data.frame(if_else(pred_trn_resp > 0.4, 1, -1))
  pred_tst_resp <- predict(model, newdata = tst_data, type = "response")
  pred_tst <-as.data.frame(if_else(pred_tst_resp > 0.4, 1, -1))
  
  print(table(actual=trn_data$hiLo, preds=pred_trn[,1])) 
  print(table(actual=tst_data$hiLo, preds=pred_tst[,1]))
  
  roc(trn_data$hiLo, pred_trn[,1], plot=TRUE, legacy.axes=TRUE, xlab="False Positive Rate", ylab="True Postive Rate", col="#377eb8", lwd=4, print.auc=TRUE)
  plot.roc(tst_data$hiLo, pred_tst[,1], col="#4daf4a", lwd=4, print.auc=TRUE, print.auc.y = 0.45, add=TRUE)
  legend("bottomright", legend=c("Training", "Test"), col=c("#377eb8", "#4daf4a"), lwd=4)
}

#Bing
evalTrainTestLM(glmModel1, x1, x1_tst)

#NRC
evalTrainTestLM(glmModel2, x2, x2_tst)

#AFINN
evalTrainTestLM(glmModel3, x3, x3_tst)

#Combined - Bing, NRC, AFINN
evalTrainTestLM(glmModel4, x4, x4_tst)

#Broader set of words
evalTrainTestLM(glmModel5, x5, x5_tst)
```



